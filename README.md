# DeepLearningTasks

A collection of three deep learning tasks implemented in Python. Each task (folder) includes a report in PDF format presenting the results and insights gained from experimentation.

## Neural Network Implementation & Training (Task 1)
Implementing and training a neural network, covering fundamental deep learning concepts. The task includes backpropagation calculations, network implementation, regularization, optimizer integration, learning rate decay, and training on the CIFAR-10 dataset. The objective is to experiment with various network configurations and training techniques to analyze their impact on classification accuracy.

## ResNet, Segmentation & Colorization (Task 2)
Focusing on advanced deep learning tasks, including implementing and training a ResNet model for classification, extending it for semantic segmentation (FCN-32s & U-Net), and using U-Net for image colorization. The goal is to analyze model architectures, compare performance, and experiment with different network configurations.

## LSTM & Transformer Implementation (Task 3)
Focusing on sequence modeling with deep learning. The task includes implementing and training an LSTM network for character-level text generation and a Transformer-like model with scaled dot-product attention and masked multi-head attention. The goal is to analyze text generation techniques, compare different sampling methods, and evaluate the impact of sequence length during training.